{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f48d439",
   "metadata": {},
   "source": [
    "## Problem Statement:\n",
    "\n",
    "Create a simple language n-grams model that predicts the next word in a sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7d1966",
   "metadata": {},
   "source": [
    "### Data collection and pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4a68ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import gutenberg, reuters\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "import math\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58d7c993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "064b2bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4250"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gutenberg.sents('whitman-leaves.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff33395d",
   "metadata": {},
   "source": [
    "## Example sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb1e9928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Here',\n",
       "  'are',\n",
       "  'our',\n",
       "  'thoughts',\n",
       "  ',',\n",
       "  'voyagers',\n",
       "  \"'\",\n",
       "  'thoughts',\n",
       "  ',',\n",
       "  'Here',\n",
       "  'not',\n",
       "  'the',\n",
       "  'land',\n",
       "  ',',\n",
       "  'firm',\n",
       "  'land',\n",
       "  ',',\n",
       "  'alone',\n",
       "  'appears',\n",
       "  ',',\n",
       "  'may',\n",
       "  'then',\n",
       "  'by',\n",
       "  'them',\n",
       "  'be',\n",
       "  'said',\n",
       "  ',',\n",
       "  'The',\n",
       "  'sky',\n",
       "  'o',\n",
       "  \"'\",\n",
       "  'erarches',\n",
       "  'here',\n",
       "  ',',\n",
       "  'we',\n",
       "  'feel',\n",
       "  'the',\n",
       "  'undulating',\n",
       "  'deck',\n",
       "  'beneath',\n",
       "  'our',\n",
       "  'feet',\n",
       "  ',',\n",
       "  'We',\n",
       "  'feel',\n",
       "  'the',\n",
       "  'long',\n",
       "  'pulsation',\n",
       "  ',',\n",
       "  'ebb',\n",
       "  'and',\n",
       "  'flow',\n",
       "  'of',\n",
       "  'endless',\n",
       "  'motion',\n",
       "  ',',\n",
       "  'The',\n",
       "  'tones',\n",
       "  'of',\n",
       "  'unseen',\n",
       "  'mystery',\n",
       "  ',',\n",
       "  'the',\n",
       "  'vague',\n",
       "  'and',\n",
       "  'vast',\n",
       "  'suggestions',\n",
       "  'of',\n",
       "  'the',\n",
       "  'briny',\n",
       "  'world',\n",
       "  ',',\n",
       "  'the',\n",
       "  'liquid',\n",
       "  '-',\n",
       "  'flowing',\n",
       "  'syllables',\n",
       "  ',',\n",
       "  'The',\n",
       "  'perfume',\n",
       "  ',',\n",
       "  'the',\n",
       "  'faint',\n",
       "  'creaking',\n",
       "  'of',\n",
       "  'the',\n",
       "  'cordage',\n",
       "  ',',\n",
       "  'the',\n",
       "  'melancholy',\n",
       "  'rhythm',\n",
       "  ',',\n",
       "  'The',\n",
       "  'boundless',\n",
       "  'vista',\n",
       "  'and',\n",
       "  'the',\n",
       "  'horizon',\n",
       "  'far',\n",
       "  'and',\n",
       "  'dim',\n",
       "  'are',\n",
       "  'all',\n",
       "  'here',\n",
       "  ',',\n",
       "  'And',\n",
       "  'this',\n",
       "  'is',\n",
       "  'ocean',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'poem',\n",
       "  '.'],\n",
       " ['Then',\n",
       "  'falter',\n",
       "  'not',\n",
       "  'O',\n",
       "  'book',\n",
       "  ',',\n",
       "  'fulfil',\n",
       "  'your',\n",
       "  'destiny',\n",
       "  ',',\n",
       "  'You',\n",
       "  'not',\n",
       "  'a',\n",
       "  'reminiscence',\n",
       "  'of',\n",
       "  'the',\n",
       "  'land',\n",
       "  'alone',\n",
       "  ',',\n",
       "  'You',\n",
       "  'too',\n",
       "  'as',\n",
       "  'a',\n",
       "  'lone',\n",
       "  'bark',\n",
       "  'cleaving',\n",
       "  'the',\n",
       "  'ether',\n",
       "  ',',\n",
       "  'purpos',\n",
       "  \"'\",\n",
       "  'd',\n",
       "  'I',\n",
       "  'know',\n",
       "  'not',\n",
       "  'whither',\n",
       "  ',',\n",
       "  'yet',\n",
       "  'ever',\n",
       "  'full',\n",
       "  'of',\n",
       "  'faith',\n",
       "  ',',\n",
       "  'Consort',\n",
       "  'to',\n",
       "  'every',\n",
       "  'ship',\n",
       "  'that',\n",
       "  'sails',\n",
       "  ',',\n",
       "  'sail',\n",
       "  'you',\n",
       "  '!'],\n",
       " ['Bear',\n",
       "  'forth',\n",
       "  'to',\n",
       "  'them',\n",
       "  'folded',\n",
       "  'my',\n",
       "  'love',\n",
       "  ',',\n",
       "  '(',\n",
       "  'dear',\n",
       "  'mariners',\n",
       "  ',',\n",
       "  'for',\n",
       "  'you',\n",
       "  'I',\n",
       "  'fold',\n",
       "  'it',\n",
       "  'here',\n",
       "  'in',\n",
       "  'every',\n",
       "  'leaf',\n",
       "  ';)',\n",
       "  'Speed',\n",
       "  'on',\n",
       "  'my',\n",
       "  'book',\n",
       "  '!'],\n",
       " ['spread',\n",
       "  'your',\n",
       "  'white',\n",
       "  'sails',\n",
       "  'my',\n",
       "  'little',\n",
       "  'bark',\n",
       "  'athwart',\n",
       "  'the',\n",
       "  'imperious',\n",
       "  'waves',\n",
       "  ',',\n",
       "  'Chant',\n",
       "  'on',\n",
       "  ',',\n",
       "  'sail',\n",
       "  'on',\n",
       "  ',',\n",
       "  'bear',\n",
       "  'o',\n",
       "  \"'\",\n",
       "  'er',\n",
       "  'the',\n",
       "  'boundless',\n",
       "  'blue',\n",
       "  'from',\n",
       "  'me',\n",
       "  'to',\n",
       "  'every',\n",
       "  'sea',\n",
       "  ',',\n",
       "  'This',\n",
       "  'song',\n",
       "  'for',\n",
       "  'mariners',\n",
       "  'and',\n",
       "  'all',\n",
       "  'their',\n",
       "  'ships',\n",
       "  '.'],\n",
       " ['}', 'To', 'Foreign', 'Lands'],\n",
       " ['I',\n",
       "  'heard',\n",
       "  'that',\n",
       "  'you',\n",
       "  'ask',\n",
       "  \"'\",\n",
       "  'd',\n",
       "  'for',\n",
       "  'something',\n",
       "  'to',\n",
       "  'prove',\n",
       "  'this',\n",
       "  'puzzle',\n",
       "  'the',\n",
       "  'New',\n",
       "  'World',\n",
       "  ',',\n",
       "  'And',\n",
       "  'to',\n",
       "  'define',\n",
       "  'America',\n",
       "  ',',\n",
       "  'her',\n",
       "  'athletic',\n",
       "  'Democracy',\n",
       "  ',',\n",
       "  'Therefore',\n",
       "  'I',\n",
       "  'send',\n",
       "  'you',\n",
       "  'my',\n",
       "  'poems',\n",
       "  'that',\n",
       "  'you',\n",
       "  'behold',\n",
       "  'in',\n",
       "  'them',\n",
       "  'what',\n",
       "  'you',\n",
       "  'wanted',\n",
       "  '.'],\n",
       " ['}', 'To', 'a', 'Historian'],\n",
       " ['You',\n",
       "  'who',\n",
       "  'celebrate',\n",
       "  'bygones',\n",
       "  ',',\n",
       "  'Who',\n",
       "  'have',\n",
       "  'explored',\n",
       "  'the',\n",
       "  'outward',\n",
       "  ',',\n",
       "  'the',\n",
       "  'surfaces',\n",
       "  'of',\n",
       "  'the',\n",
       "  'races',\n",
       "  ',',\n",
       "  'the',\n",
       "  'life',\n",
       "  'that',\n",
       "  'has',\n",
       "  'exhibited',\n",
       "  'itself',\n",
       "  ',',\n",
       "  'Who',\n",
       "  'have',\n",
       "  'treated',\n",
       "  'of',\n",
       "  'man',\n",
       "  'as',\n",
       "  'the',\n",
       "  'creature',\n",
       "  'of',\n",
       "  'politics',\n",
       "  ',',\n",
       "  'aggregates',\n",
       "  ',',\n",
       "  'rulers',\n",
       "  'and',\n",
       "  'priests',\n",
       "  ',',\n",
       "  'I',\n",
       "  ',',\n",
       "  'habitan',\n",
       "  'of',\n",
       "  'the',\n",
       "  'Alleghanies',\n",
       "  ',',\n",
       "  'treating',\n",
       "  'of',\n",
       "  'him',\n",
       "  'as',\n",
       "  'he',\n",
       "  'is',\n",
       "  'in',\n",
       "  'himself',\n",
       "  'in',\n",
       "  'his',\n",
       "  'own',\n",
       "  'rights',\n",
       "  ',',\n",
       "  'Pressing',\n",
       "  'the',\n",
       "  'pulse',\n",
       "  'of',\n",
       "  'the',\n",
       "  'life',\n",
       "  'that',\n",
       "  'has',\n",
       "  'seldom',\n",
       "  'exhibited',\n",
       "  'itself',\n",
       "  ',',\n",
       "  '(',\n",
       "  'the',\n",
       "  'great',\n",
       "  'pride',\n",
       "  'of',\n",
       "  'man',\n",
       "  'in',\n",
       "  'himself',\n",
       "  ',)',\n",
       "  'Chanter',\n",
       "  'of',\n",
       "  'Personality',\n",
       "  ',',\n",
       "  'outlining',\n",
       "  'what',\n",
       "  'is',\n",
       "  'yet',\n",
       "  'to',\n",
       "  'be',\n",
       "  ',',\n",
       "  'I',\n",
       "  'project',\n",
       "  'the',\n",
       "  'history',\n",
       "  'of',\n",
       "  'the',\n",
       "  'future',\n",
       "  '.'],\n",
       " ['}', 'To', 'Thee', 'Old', 'Cause'],\n",
       " ['To', 'thee', 'old', 'cause', '!']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gutenberg.sents('whitman-leaves.txt')[15:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8c3f484",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = gutenberg.raw('austen-emma.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc50cec7",
   "metadata": {},
   "source": [
    "## Cleaning the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6008cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \n",
    "    #Changing to lowerecase\n",
    "    text = text.lower()\n",
    "    # Removing URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    # Remove special characters\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    # Replace numbers with nothing\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # Remove single characters\n",
    "    text = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', text)\n",
    "    # Remove extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text, flags=re.I)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51e33be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text = clean_text(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68f0083",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "010cabd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = word_tokenize(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "569321dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma',\n",
       " 'by',\n",
       " 'jane',\n",
       " 'austen',\n",
       " 'volume',\n",
       " 'chapter',\n",
       " 'emma',\n",
       " 'woodhouse',\n",
       " 'handsome',\n",
       " 'clever',\n",
       " 'and',\n",
       " 'rich',\n",
       " 'with',\n",
       " 'comfortable',\n",
       " 'home',\n",
       " 'and',\n",
       " 'happy',\n",
       " 'disposition',\n",
       " 'seemed',\n",
       " 'to']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d54d76",
   "metadata": {},
   "source": [
    "## n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a048027",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ngrams(tokens, n):\n",
    "    n_grams = ngrams(tokens, n)\n",
    "    n_grams_freq = Counter(n_grams)\n",
    "    return n_grams_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "653c949e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = generate_ngrams(tokens, 2)\n",
    "trigrams = generate_ngrams(tokens, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0610716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common bigrams: [(('to', 'be'), 607), (('of', 'the'), 566), (('it', 'was'), 448), (('in', 'the'), 446), (('she', 'had'), 332), (('she', 'was'), 328), (('had', 'been'), 309), (('mr', 'knightley'), 300), (('it', 'is'), 299), (('could', 'not'), 278)]\n",
      "Most common trigrams: [(('she', 'could', 'not'), 72), (('it', 'would', 'be'), 63), (('would', 'have', 'been'), 60), (('do', 'not', 'know'), 55), (('it', 'was', 'not'), 55), (('she', 'had', 'been'), 53), (('mr', 'frank', 'churchill'), 50), (('in', 'the', 'world'), 49), (('could', 'not', 'be'), 45), (('it', 'will', 'be'), 42)]\n"
     ]
    }
   ],
   "source": [
    "#10 most common bigrams and trigrams\n",
    "print(\"Most common bigrams:\", bigrams.most_common(10))\n",
    "print(\"Most common trigrams:\", trigrams.most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e01fc63",
   "metadata": {},
   "source": [
    "## Probability of a word given (n-1) gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bedfed22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_probability(tokens, sequence, token, n):\n",
    "    \n",
    "    #n-grams\n",
    "    ngram_freq = generate_ngrams(tokens,n)\n",
    "    n1gram_freq = generate_ngrams(tokens,n-1)\n",
    "        \n",
    "    seq = tuple(sequence)\n",
    "    seq_freq = n1gram_freq.get(seq, 0)\n",
    "        \n",
    "    # Get the frequency of the n-gram (context followed by the word)\n",
    "    n_gram = seq + (token,)\n",
    "    n_gram_freq = ngram_freq.get(n_gram, 0)\n",
    "    \n",
    "    # Calculate the probability\n",
    "    if seq_freq == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return n_gram_freq / seq_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65bb8a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of churchill after ['mr', 'frank'] is 1.0\n"
     ]
    }
   ],
   "source": [
    "sequence = ['mr','frank']\n",
    "token = 'churchill'\n",
    "\n",
    "probability = calculate_probability(tokens, sequence, token, 3)\n",
    "print(f'Probability of {token} after {sequence} is {probability}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3869b927",
   "metadata": {},
   "source": [
    "## Predict next word given a set of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ccf44867",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_word(tokens,sequence,n):\n",
    "    \n",
    "    ngram_freq = generate_ngrams(tokens,n)\n",
    "    n1gram_freq = generate_ngrams(tokens,n-1)\n",
    "    \n",
    "    possible_words = set(tokens)\n",
    "    next_possible_word = None\n",
    "    max_prob = 0\n",
    "    \n",
    "    for word in possible_words:\n",
    "        prob = calculate_probability(tokens, sequence, word, 3)\n",
    "        if prob > max_prob:\n",
    "            max_prob = prob\n",
    "            next_possible_word = word\n",
    "    return next_possible_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70680c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted next word following the context '['churchill', 'was']' is 'looking'\n"
     ]
    }
   ],
   "source": [
    "n = 3\n",
    "context = ['churchill', 'was']\n",
    "predicted_word = predict_next_word(tokens, context, 3)\n",
    "print(f\"The predicted next word following the context '{context}' is '{predicted_word}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "748eb41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looking\n"
     ]
    }
   ],
   "source": [
    "print(predicted_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0d2273a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(tokens, prefix, n, length):\n",
    "    n_grams_freq = generate_ngrams(tokens, n)\n",
    "    n_minus_1_grams_freq = generate_ngrams(tokens, n-1)\n",
    "    sentence = list(prefix)\n",
    "    \n",
    "    while len(sentence) < length:\n",
    "        seq = sentence[-(n-1):]\n",
    "        next_word = predict_next_word(tokens, seq, n)\n",
    "        if next_word is None:\n",
    "            break\n",
    "        sentence.append(next_word)\n",
    "    \n",
    "    return ' '.join(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dab82efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The generated sentence is: 'churchill was looking on unconcerned jane was quite at loss'\n"
     ]
    }
   ],
   "source": [
    "n = 3\n",
    "prefix = ['churchill', 'was']\n",
    "length = 10\n",
    "sentence = generate_sentence(tokens, prefix, n, length)\n",
    "print(f\"The generated sentence is: '{sentence}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3793a9ef",
   "metadata": {},
   "source": [
    "## Laplace smoothing\n",
    "\n",
    " This is a method to handle unseen n-grams so that there is no 0 probability of any n-gram. This is done by modifying the probability calculation to account for unseen n-grams. It adds a count of 1 to every possible n-gram\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "791f1392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The generated sentence with Laplace is: 'emma saw his son in law and generally strong sense'\n"
     ]
    }
   ],
   "source": [
    "def generate_ngrams(tokens, n):\n",
    "    n_grams = ngrams(tokens, n)\n",
    "    n_grams_freq = Counter(n_grams)\n",
    "    return n_grams_freq\n",
    "\n",
    "def calculate_probability_laplace(sequence, token, n_grams_freq, n_minus_1_grams_freq, vocab_size, k=1):\n",
    "    seq = tuple(sequence)\n",
    "    seq_freq = n_minus_1_grams_freq.get(seq, 0)\n",
    "    n_gram = seq + (token,)\n",
    "    n_gram_freq = n_grams_freq.get(n_gram, 0)\n",
    "    \n",
    "    if seq_freq == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return (n_gram_freq + k) / (seq_freq + k * vocab_size)\n",
    "\n",
    "''''def calculate_probability_laplace(tokens, prefix, ngram_counts, ngram_total_counts, vocabulary_size, n, k=1):\n",
    "    probabilities = []\n",
    "    start_index = len(prefix)\n",
    "    for i in range(start_index, len(tokens)):\n",
    "        ngram = tuple(tokens[i-n+1:i+1])\n",
    "        ngram_count = ngram_counts[ngram]\n",
    "        context_count = ngram_total_counts[ngram[:-1]]\n",
    "        probability = (ngram_count + k) / (context_count + k * vocabulary_size)\n",
    "        probabilities.append(probability)\n",
    "    return probabilities '''\n",
    "\n",
    "def predict_next_word_laplace(tokens, sequence, n_grams_freq, n_minus_1_grams_freq, vocab_size):\n",
    "    possible_words = set(tokens)\n",
    "    next_possible_word = None\n",
    "    max_prob = 0\n",
    "    \n",
    "    for word in possible_words:\n",
    "        prob = calculate_probability_laplace(sequence, word, n_grams_freq, n_minus_1_grams_freq, vocab_size,1)\n",
    "        if prob > max_prob:\n",
    "            max_prob = prob\n",
    "            next_possible_word = word\n",
    "    return next_possible_word\n",
    "\n",
    "def generate_sentence_laplace(tokens, prefix, n, length):\n",
    "    n_grams_freq = generate_ngrams(tokens, n)\n",
    "    n_minus_1_grams_freq = generate_ngrams(tokens, n-1)\n",
    "    vocab_size = len(set(tokens))\n",
    "    \n",
    "    sentence = list(prefix)\n",
    "    \n",
    "    while len(sentence) < length:\n",
    "        seq = sentence[-(n-1):]\n",
    "        next_word = predict_next_word_laplace(tokens, seq, n_grams_freq, n_minus_1_grams_freq, vocab_size)\n",
    "        if next_word is None:\n",
    "            break\n",
    "        sentence.append(next_word)\n",
    "    \n",
    "    return ' '.join(sentence)\n",
    "\n",
    "# Example usage with various (n-1)-gram sequences\n",
    "n = 3\n",
    "prefix = ['emma', 'saw']\n",
    "length = 10\n",
    "sentence = generate_sentence_laplace(tokens, prefix, n, length)\n",
    "print(f\"The generated sentence with Laplace is: '{sentence}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd317c46",
   "metadata": {},
   "source": [
    "## Testing and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e138525",
   "metadata": {},
   "source": [
    "### Test the model by inputting various (n − 1)-gram sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "634a0a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequence: ['Baseball', 'is']\n",
      "Generated sentence: 'Baseball is'\n",
      "\n",
      "Input sequence: ['seasons', 'will', 'bring']\n",
      "Generated sentence: 'seasons will bring him soon continued mrs weston was the'\n",
      "\n",
      "Input sequence: ['i', 'sing', 'to']\n",
      "Generated sentence: 'i sing to her and she was not to be'\n",
      "\n",
      "Input sequence: ['think', 'in', 'silence']\n",
      "Generated sentence: 'think in silence smiles of intelligence passed between them emma'\n",
      "\n",
      "Input sequence: ['ponder', 'in', 'silence']\n",
      "Generated sentence: 'ponder in silence smiles of intelligence passed between them emma'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_sequences = [\n",
    "    ['Baseball', 'is'],\n",
    "    ['seasons','will','bring'],\n",
    "    ['i','sing','to'],\n",
    "    ['think','in','silence'],\n",
    "    ['ponder','in','silence']\n",
    "]\n",
    "\n",
    "n = 3  # Using trigrams\n",
    "length = 10  # Desired length of the generated sentence\n",
    "\n",
    "for seq in test_sequences:\n",
    "    sentence = generate_sentence_laplace(tokens, seq, n, length)\n",
    "    print(f\"Input sequence: {seq}\")\n",
    "    print(f\"Generated sentence: '{sentence}'\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510e3224",
   "metadata": {},
   "source": [
    "## Perplexity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "226e5fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_probability(tokens, ngram_counts, ngram_total_counts, vocabulary_size, n, k=1):\n",
    "    probabilities = []\n",
    "    for i in range(n-1, len(tokens)):\n",
    "        ngram = tuple(tokens[i-n+1:i+1])\n",
    "        ngram_count = ngram_counts[ngram]\n",
    "        context_count = ngram_total_counts[ngram[:-1]]\n",
    "        probability = (ngram_count + k) / (context_count + k * vocabulary_size)\n",
    "        probabilities.append(probability)\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3bcf0f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'def calculate_perplexity_1(tokens, n, n_grams_freq, n_minus_1_grams_freq, vocab_size):\\n    log_prob_sum = 0\\n    n_tokens = len(tokens)\\n    \\n    for i in range(n_tokens - n + 1):\\n        seq = tokens[i:i+n-1]\\n        target = tokens[i+n-1]\\n        prob = calculate_probability_laplace(seq, target, n_grams_freq, n_minus_1_grams_freq, vocab_size,1)\\n        if prob > 0:\\n            print('probability greater than 0: ',log_prob_sum)\\n            log_prob_sum += math.log(prob)\\n        else:\\n            log_prob_sum += float('-inf')  # Handle zero probability\\n            print('probability less than 0: ',log_prob_sum)\\n    \\n    perplexity = math.exp(-log_prob_sum / (n_tokens - n + 1))\\n    return perplexity \""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''''def calculate_perplexity_1(tokens, n, n_grams_freq, n_minus_1_grams_freq, vocab_size):\n",
    "    log_prob_sum = 0\n",
    "    n_tokens = len(tokens)\n",
    "    \n",
    "    for i in range(n_tokens - n + 1):\n",
    "        seq = tokens[i:i+n-1]\n",
    "        target = tokens[i+n-1]\n",
    "        prob = calculate_probability_laplace(seq, target, n_grams_freq, n_minus_1_grams_freq, vocab_size,1)\n",
    "        if prob > 0:\n",
    "            print('probability greater than 0: ',log_prob_sum)\n",
    "            log_prob_sum += math.log(prob)\n",
    "        else:\n",
    "            log_prob_sum += float('-inf')  # Handle zero probability\n",
    "            print('probability less than 0: ',log_prob_sum)\n",
    "    \n",
    "    perplexity = math.exp(-log_prob_sum / (n_tokens - n + 1))\n",
    "    return perplexity '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db51c6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_perplexity(tokens, ngram_counts, ngram_total_counts, vocabulary_size, n, k=1):\n",
    "    probabilities = calculate_probability(tokens, ngram_counts, ngram_total_counts, vocabulary_size, k)\n",
    "    log_prob_sum = sum(math.log(p) for p in probabilities if p > 0)\n",
    "    perplexity = math.exp(-log_prob_sum / len(probabilities))\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe6f273",
   "metadata": {},
   "source": [
    "train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "47585601",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.75 * len(tokens))\n",
    "train_tokens = tokens[:train_size]\n",
    "test_tokens = tokens[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6eee5e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_grams_freq = generate_ngrams(train_tokens, n)\n",
    "n_minus_1_grams_freq = generate_ngrams(train_tokens, n-1)\n",
    "vocab_size = len(set(train_tokens))\n",
    "n = 3\n",
    "\n",
    "perplexity_score = calculate_perplexity(test_tokens, n_grams_freq, n_minus_1_grams_freq, vocab_size, n, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c44519c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6424.000000021067"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "33559408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram Perplexity: 1492.821411101309\n",
      "Trigram Perplexity: 4916.402326143414\n"
     ]
    }
   ],
   "source": [
    "def evaluate_ngram_model(n):\n",
    "    n_grams_freq = generate_ngrams(train_tokens, n)\n",
    "    n_minus_1_grams_freq = generate_ngrams(train_tokens, n-1)\n",
    "    vocab_size = len(set(train_tokens))\n",
    "    perplexity = calculate_perplexity(test_tokens, n_grams_freq, n_minus_1_grams_freq, vocab_size, n, n)\n",
    "    return perplexity\n",
    "\n",
    "# Evaluate bigram and trigram models\n",
    "bigram_perplexity = evaluate_ngram_model(2)\n",
    "trigram_perplexity = evaluate_ngram_model(3)\n",
    "\n",
    "print(f\"Bigram Perplexity: {bigram_perplexity}\")\n",
    "print(f\"Trigram Perplexity: {trigram_perplexity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c6ee737b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigram Perplexity: 4916.402326143414\n",
      "Quadgram Perplexity: 6214.487301508134\n"
     ]
    }
   ],
   "source": [
    "trigram_perplexity = evaluate_ngram_model(3)\n",
    "quadigram_perplexity = evaluate_ngram_model(4)\n",
    "\n",
    "print(f\"Trigram Perplexity: {trigram_perplexity}\")\n",
    "print(f\"Quadgram Perplexity: {quadigram_perplexity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f36cb263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pentagram Perplexity: 6394.184532890865\n",
      "Hexgram Perplexity: 6418.13182790551\n"
     ]
    }
   ],
   "source": [
    "pentagram_perplexity = evaluate_ngram_model(5)\n",
    "hexagram_perplexity = evaluate_ngram_model(6)\n",
    "\n",
    "print(f\"Pentagram Perplexity: {pentagram_perplexity}\")\n",
    "print(f\"Hexgram Perplexity: {hexagram_perplexity}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d46cdcb",
   "metadata": {},
   "source": [
    "## Analysis of results\n",
    "\n",
    "After evaluating different n-gram models, it's clear that the bigram model performs the best, with a perplexity score of around 1493. This means it predicts the test data better than models that consider more context, like trigrams or higher n-grams.\n",
    "\n",
    "As we increase the context from trigrams to hexagrams, the perplexity score actually worsens. For instance, the trigram model has a perplexity of about 4916, and this trend continues upwards with quadgrams, pentagrams, and hexagrams reaching scores above 6418.\n",
    "\n",
    "The main reason for this pattern is likely due to data sparsity. Higher n-grams need more data to make accurate predictions because they consider more words in their context. Without sufficient data, the models struggle to make reliable predictions, leading to higher perplexity. Essentially, the models have less information to learn from, making them less effective.\n",
    "\n",
    "On the other hand, the bigram model strikes a good balance. It uses just enough context to make informed predictions without requiring an overwhelming amount of data. This simplicity makes it more robust, especially with the relatively smaller dataset we have from Gutenberg Whitman text.\n",
    "\n",
    "In summary, for our specific dataset, sticking with a simpler bigram model is more effective than using more complex models that need more data to perform well. This insight underscores the importance of balancing model complexity with the amount of data available. In scenarios with richer data, more complex models might shine, but here, simplicity wins."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0f6c12",
   "metadata": {},
   "source": [
    "## Report on the performance and results\n",
    "\n",
    "In conclusion, higher order n-grams require more data to make accurate text predictions. With the data we have, the higher n-grams are not performing well because adding more words for context while having less data on the whole makes the perplexity score worse.\n",
    "\n",
    "For this data, the bigram model finds strikes a balance, using just enough context to make good predictions without requiring too much data. When we increase the context by using higher n-grams, we end up with less reliable probability estimates and higher perplexity.\n",
    "\n",
    "More complex n-gram models can overfit the training data, meaning they perform well on the data they were trained on but poorly on new, unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c13d52e",
   "metadata": {},
   "source": [
    "## With UI code with PyQt5 - Please run these cells and GUI comes up prompting to enter inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01e9dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install PyQt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe641a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyQt5.QtWidgets import QApplication, QWidget, QVBoxLayout, QLabel, QLineEdit, QPushButton, QTextEdit, QMessageBox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba1f225",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCompletionApp(QWidget):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.initUI()\n",
    "        \n",
    "    def initUI(self):\n",
    "        layout = QVBoxLayout()\n",
    "\n",
    "        self.prefix_label = QLabel('Enter Prefix sentence:')\n",
    "        layout.addWidget(self.prefix_label)\n",
    "        \n",
    "        self.prefix_input = QLineEdit(self)\n",
    "        layout.addWidget(self.prefix_input)\n",
    "        \n",
    "        self.length_label = QLabel('Enter length of the sentence you to generate:')\n",
    "        layout.addWidget(self.length_label)\n",
    "        \n",
    "        self.length_input = QLineEdit(self)\n",
    "        layout.addWidget(self.length_input)\n",
    "        \n",
    "        self.generate_button = QPushButton('Generate', self)\n",
    "        self.generate_button.clicked.connect(self.on_generate_click)\n",
    "        layout.addWidget(self.generate_button)\n",
    "        \n",
    "        self.result_label = QLabel('Generated Text:')\n",
    "        layout.addWidget(self.result_label)\n",
    "        \n",
    "        self.result_text = QTextEdit(self)\n",
    "        self.result_text.setReadOnly(True)\n",
    "        layout.addWidget(self.result_text)\n",
    "        \n",
    "        self.setLayout(layout)\n",
    "        self.setWindowTitle('Text Completion using N-gram Model')\n",
    "        self.show()\n",
    "        \n",
    "    def on_generate_click(self):\n",
    "        prefix = self.prefix_input.text().strip().lower().split()\n",
    "        length = self.length_input.text().strip()\n",
    "        \n",
    "        if not length.isdigit():\n",
    "            QMessageBox.warning(self, 'Error', 'Length must be a number.')\n",
    "            return\n",
    "        \n",
    "        length = int(length)\n",
    "        \n",
    "        if len(prefix) < n-1:\n",
    "            QMessageBox.warning(self, 'Error', f'Prefix must be at least {n-1} words long.')\n",
    "            return\n",
    "        \n",
    "        \n",
    "        print('prefix is: ', prefix)\n",
    "        generated_sentence = generate_sentence_laplace(tokens, prefix, n, length)\n",
    "        self.result_text.setText(generated_sentence)\n",
    "\n",
    "n = 3 \n",
    "\n",
    "# Run the PyQt5 application\n",
    "if __name__ == '__main__':\n",
    "    app = QApplication(sys.argv)\n",
    "    ex = TextCompletionApp()\n",
    "    sys.exit(app.exec_())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07937a3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57b55d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
