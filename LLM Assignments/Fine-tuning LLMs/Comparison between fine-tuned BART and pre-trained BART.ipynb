{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc0bd1eb",
   "metadata": {},
   "source": [
    "### Agenda:\n",
    "\n",
    "In this notebook I just want to see how well the pre-trained model and the fine-tuned model summarize the conversations. Comparison will be done on coherence, and facts presentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7517202f",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21bf2f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: no matches found: transformers[torch]\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install datasets evaluate rouge_score py7zr -q accelerate peft bitsandbytes transformers[torch] trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "812d2120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: peft in /Users/divyahegde/anaconda3/lib/python3.10/site-packages (0.11.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/divyahegde/anaconda3/lib/python3.10/site-packages (from peft) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/divyahegde/anaconda3/lib/python3.10/site-packages (from peft) (23.2)\n",
      "Requirement already satisfied: psutil in /Users/divyahegde/anaconda3/lib/python3.10/site-packages (from peft) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /Users/divyahegde/anaconda3/lib/python3.10/site-packages (from peft) (6.0)\n",
      "Requirement already satisfied: torch>=1.13.0 in /Users/divyahegde/anaconda3/lib/python3.10/site-packages (from peft) (2.3.1)\n",
      "Requirement already satisfied: transformers in /Users/divyahegde/anaconda3/lib/python3.10/site-packages (from peft) (4.24.0)\n",
      "Requirement already satisfied: tqdm in /Users/divyahegde/anaconda3/lib/python3.10/site-packages (from peft) (4.66.4)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /Users/divyahegde/anaconda3/lib/python3.10/site-packages (from peft) (0.32.1)\n",
      "Requirement already satisfied: safetensors in /Users/divyahegde/anaconda3/lib/python3.10/site-packages (from peft) (0.4.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in /Users/divyahegde/anaconda3/lib/python3.10/site-packages (from peft) (0.23.4)\n",
      "Requirement already satisfied: filelock in /Users/divyahegde/anaconda3/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/divyahegde/anaconda3/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2024.5.0)\n",
      "Requirement already satisfied: requests in /Users/divyahegde/anaconda3/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/divyahegde/anaconda3/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.11.0)\n",
      "Requirement already satisfied: sympy in /Users/divyahegde/anaconda3/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/divyahegde/anaconda3/lib/python3.10/site-packages (from torch>=1.13.0->peft) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in /Users/divyahegde/anaconda3/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/divyahegde/anaconda3/lib/python3.10/site-packages (from transformers->peft) (2022.7.9)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/divyahegde/anaconda3/lib/python3.10/site-packages (from transformers->peft) (0.11.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/divyahegde/anaconda3/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/divyahegde/anaconda3/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/divyahegde/anaconda3/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/divyahegde/anaconda3/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/divyahegde/anaconda3/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/divyahegde/anaconda3/lib/python3.10/site-packages/mpmath-1.2.1-py3.10.egg (from sympy->torch>=1.13.0->peft) (1.2.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Users/divyahegde/anaconda3/bin/python -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0115b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "from peft import PeftModel, PeftConfig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f25fde8",
   "metadata": {},
   "source": [
    "### Pre-trained BART model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7792b700",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/divyahegde/anaconda3/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/Users/divyahegde/anaconda3/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3497b35dcd574c0b96297b7bc2f293bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BartForConditionalGeneration were not initialized from the model checkpoint at facebook/bart-large-cnn and are newly initialized: ['model.encoder.embed_tokens.weight', 'model.shared.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a44b16d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Generic function to generate summary and present it against the summary from the dataset\n",
    "def generate_summary(input, llm):\n",
    "    \"\"\"Prepare prompt  -->  tokenize -->  generate output using LLM  -->  detokenize output\"\"\"\n",
    "\n",
    "    input_prompt = f\"\"\"\n",
    "                    Summarize the following conversation.\n",
    "\n",
    "                    {input}\n",
    "\n",
    "                    Summary:\n",
    "                    \"\"\"\n",
    "\n",
    "    input_ids = tokenizer(input_prompt, return_tensors='pt')\n",
    "    tokenized_output = llm.generate(input_ids=input_ids['input_ids'], min_length=30, max_length=200, )\n",
    "    output = tokenizer.decode(tokenized_output[0], skip_special_tokens=True)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80575b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import get_peft_model, PeftConfig,PeftModelForSeq2SeqLM, AutoPeftModel,AutoPeftModelForSeq2SeqLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5fbd0b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BartForConditionalGeneration were not initialized from the model checkpoint at facebook/bart-large-cnn and are newly initialized: ['model.encoder.embed_tokens.weight', 'model.shared.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5422d76efad4516b3bd58f0ef860c00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.24k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bf448eab3c64ad191126ab314b0ba6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f8f31616bd2465ba04dad25f708fd70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a76d41c6aabb48139592a6cbc6c46bd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2fe1111c00942c1a74f948edbdc01db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/278 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "145b75fa94624ecfabf2cdb981189446",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/4.74M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loaded_peft_model = AutoPeftModelForSeq2SeqLM.from_pretrained('divyahegde07/mode_tuned_peft')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e94958",
   "metadata": {},
   "source": [
    "Splitting the dataste into test and train to pick some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb6c3469",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = load_dataset(\"samsum\",split='test')\n",
    "train_data = load_dataset(\"samsum\",split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b18d49a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample\n",
      "Hannah: Hey, do you have Betty's number?\n",
      "Amanda: Lemme check\n",
      "Hannah: <file_gif>\n",
      "Amanda: Sorry, can't find it.\n",
      "Amanda: Ask Larry\n",
      "Amanda: He called her last time we were at the park together\n",
      "Hannah: I don't know him well\n",
      "Hannah: <file_gif>\n",
      "Amanda: Don't be shy, he's very nice\n",
      "Hannah: If you say so..\n",
      "Hannah: I'd rather you texted him\n",
      "Amanda: Just text him ðŸ™‚\n",
      "Hannah: Urgh.. Alright\n",
      "Hannah: Bye\n",
      "Amanda: Bye bye\n",
      "-------------------\n",
      "Summary:\n",
      "Hannah asks Amanda for Betty's number. Amanda tries to find the number but can't find it. She asks Hannah to text Larry. Hannah says she'd rather text him.\n",
      "Ground Truth Summary:\n",
      "Hannah needs Betty's number but Amanda doesn't have it. She needs to contact Larry.\n"
     ]
    }
   ],
   "source": [
    "sample = test_data[0]['dialogue']\n",
    "label = test_data[0]['summary']\n",
    "\n",
    "output = generate_summary(sample, llm=model)\n",
    "\n",
    "print(\"Sample\")\n",
    "print(sample)\n",
    "print(\"-------------------\")\n",
    "print(\"Summary:\")\n",
    "print(output)\n",
    "print(\"Ground Truth Summary:\")\n",
    "print(label)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd8b9ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample\n",
      "Hannah: Hey, do you have Betty's number?\n",
      "Amanda: Lemme check\n",
      "Hannah: <file_gif>\n",
      "Amanda: Sorry, can't find it.\n",
      "Amanda: Ask Larry\n",
      "Amanda: He called her last time we were at the park together\n",
      "Hannah: I don't know him well\n",
      "Hannah: <file_gif>\n",
      "Amanda: Don't be shy, he's very nice\n",
      "Hannah: If you say so..\n",
      "Hannah: I'd rather you texted him\n",
      "Amanda: Just text him ðŸ™‚\n",
      "Hannah: Urgh.. Alright\n",
      "Hannah: Bye\n",
      "Amanda: Bye bye\n",
      "-------------------\n",
      "Summary:\n",
      "Amanda can't find Betty's number. She asks Hannah to text Larry, who called Betty the last time they were at the park together.\n",
      "Ground Truth Summary:\n",
      "Hannah needs Betty's number but Amanda doesn't have it. She needs to contact Larry.\n"
     ]
    }
   ],
   "source": [
    "sample = test_data[0]['dialogue']\n",
    "label = test_data[0]['summary']\n",
    "\n",
    "output = generate_summary(sample, loaded_peft_model)\n",
    "\n",
    "print(\"Sample\")\n",
    "print(sample)\n",
    "print(\"-------------------\")\n",
    "print(\"Summary:\")\n",
    "print(output)\n",
    "print(\"Ground Truth Summary:\")\n",
    "print(label)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d754a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample\n",
      "Olivia: Who are you voting for in this election? \r\n",
      "Oliver: Liberals as always.\r\n",
      "Olivia: Me too!!\r\n",
      "Oliver: Great\n",
      "-------------------\n",
      "Summary:\n",
      "Olivia and Oliver are voting in the upcoming election. Oliver is voting for the Liberal Party. Olivia wants to vote for the Republican Party. The two discuss who they will vote for.\n",
      "Ground Truth Summary:\n",
      "Olivia and Olivier are voting for liberals in this election. \n"
     ]
    }
   ],
   "source": [
    "sample = train_data[1]['dialogue']\n",
    "label = train_data[1]['summary']\n",
    "\n",
    "output = generate_summary(sample, model)\n",
    "\n",
    "print(\"Sample\")\n",
    "print(sample)\n",
    "print(\"-------------------\")\n",
    "print(\"Summary:\")\n",
    "print(output)\n",
    "print(\"Ground Truth Summary:\")\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f860d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample\n",
      "Olivia: Who are you voting for in this election? \r\n",
      "Oliver: Liberals as always.\r\n",
      "Olivia: Me too!!\r\n",
      "Oliver: Great\n",
      "-------------------\n",
      "Summary:\n",
      "Oliver is voting for Liberals as always. Olivia will vote for the Liberal Party. Oliver and Olivia are voting for the Liberals. Oliver will vote Liberal.\n",
      "Ground Truth Summary:\n",
      "Olivia and Olivier are voting for liberals in this election. \n"
     ]
    }
   ],
   "source": [
    "sample = train_data[1]['dialogue']\n",
    "label = train_data[1]['summary']\n",
    "\n",
    "output = generate_summary(sample, loaded_peft_model)\n",
    "\n",
    "print(\"Sample\")\n",
    "print(sample)\n",
    "print(\"-------------------\")\n",
    "print(\"Summary:\")\n",
    "print(output)\n",
    "print(\"Ground Truth Summary:\")\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc115ea",
   "metadata": {},
   "source": [
    "For this example, we can see that just the BART model which is trained on CNN corpus is hallucinating. It is introducing new information which is non-existant in the conversation. The fine tuned model on the other hand summarizes much better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72981436",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
